== [[HadoopFsRelation]] HadoopFsRelation -- Relation for File-Based Data Source

`HadoopFsRelation` is a link:spark-sql-BaseRelation.adoc[BaseRelation] and link:spark-sql-FileRelation.adoc[FileRelation].

`HadoopFsRelation` is <<creating-instance, created>> when:

* `HiveMetastoreCatalog` is requested to link:spark-sql-HiveMetastoreCatalog.adoc#convertToLogicalRelation[convertToLogicalRelation] (when `RelationConversions` logical evaluation rule is requested to link:spark-sql-RelationConversions.adoc#convert[convert a HiveTableRelation to a LogicalRelation] for `parquet` or `native` and `hive` ORC storage formats

* `DataSource` is requested to link:spark-sql-DataSource.adoc#resolveRelation[create a BaseRelation] (for a non-streaming file-based data source, i.e. link:spark-sql-FileFormat.adoc[FileFormat])

NOTE: The optional <<bucketSpec, BucketSpec>> is defined exclusively for a non-streaming file-based data source.

[source, scala]
----
CAUTION: Demo the different cases when `HadoopFsRelation` is created

CAUTION: Demo when `BucketSpec` is defined

// Exercise 1: spark.table for DataSource tables (provider != hive)

// Exercise 2: spark.read with format as a `FileFormat`

// Exercise 3: spark.table for Hive tables (provider == hive)
----

=== [[creating-instance]] Creating HadoopFsRelation Instance

`HadoopFsRelation` takes the following when created:

* [[location]] Location (as `FileIndex`)
* [[partitionSchema]] Partition link:spark-sql-StructType.adoc[schema]
* [[dataSchema]] Data link:spark-sql-StructType.adoc[schema]
* [[bucketSpec]] Optional link:spark-sql-BucketSpec.adoc[bucketing specification]
* [[fileFormat]] link:spark-sql-FileFormat.adoc[FileFormat]
* [[options]] Options
* [[sparkSession]] link:spark-sql-SparkSession.adoc[SparkSession]

`HadoopFsRelation` initializes the <<internal-registries, internal registries and counters>>.
