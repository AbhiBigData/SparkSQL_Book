== [[TungstenAggregationIterator]] TungstenAggregationIterator -- Iterator of UnsafeRows for HashAggregateExec Physical Operator

`TungstenAggregationIterator` is a <<spark-sql-AggregationIterator.adoc#, AggregationIterator>> that is used exclusively when the <<spark-sql-SparkPlan-HashAggregateExec.adoc#, HashAggregateExec>> aggregate physical operator is executed (to process rows per partition).

[source, scala]
----
val q = spark.range(10).
  groupBy('id % 2 as "group").
  agg(sum("id") as "sum")
val execPlan = q.queryExecution.sparkPlan
scala> println(execPlan.numberedTreeString)
00 HashAggregate(keys=[(id#0L % 2)#11L], functions=[sum(id#0L)], output=[group#3L, sum#7L])
01 +- HashAggregate(keys=[(id#0L % 2) AS (id#0L % 2)#11L], functions=[partial_sum(id#0L)], output=[(id#0L % 2)#11L, sum#13L])
02    +- Range (0, 10, step=1, splits=8)

import org.apache.spark.sql.execution.aggregate.HashAggregateExec
val hashAggExec = execPlan.asInstanceOf[HashAggregateExec]
val hashAggExecRDD = hashAggExec.execute

// MapPartitionsRDD is in private[spark] scope
// Use :paste -raw for the following helper object
package org.apache.spark
object AccessPrivateSpark {
  import org.apache.spark.rdd.RDD
  def mapPartitionsRDD[T](hashAggExecRDD: RDD[T]) = {
    import org.apache.spark.rdd.MapPartitionsRDD
    hashAggExecRDD.asInstanceOf[MapPartitionsRDD[_, _]]
  }
}
// END :paste -raw

import org.apache.spark.AccessPrivateSpark
val mpRDD = AccessPrivateSpark.mapPartitionsRDD(hashAggExecRDD)
val f = mpRDD.iterator(_, _)

import org.apache.spark.sql.execution.aggregate.TungstenAggregationIterator
// FIXME How to show that TungstenAggregationIterator is used?
----

=== [[processInputs]] `processInputs` Internal Method

[source, scala]
----
processInputs(fallbackStartsAt: (Int, Int)): Unit
----

`processInputs`...FIXME

NOTE: `processInputs` is used when `TungstenAggregationIterator` is <<creating-instance, created>> (and sets the internal flags to indicate whether to use a hash-based aggregation or, in the worst case, a sort-based aggregation when there is not enough memory for groups and their buffers).

=== [[switchToSortBasedAggregation]] `switchToSortBasedAggregation` Internal Method

[source, scala]
----
switchToSortBasedAggregation(): Unit
----

`switchToSortBasedAggregation`...FIXME

NOTE: `switchToSortBasedAggregation` is used when `TungstenAggregationIterator` <<processInputs, processInputs>> (and `externalSorter` is used).

==== [[next]] `next` Method

[source, scala]
----
next(): UnsafeRow
----

NOTE: `next` is part of Scala's http://www.scala-lang.org/api/2.11.11/#scala.collection.Iterator[scala.collection.Iterator] interface that returns the next element and discards it from the iterator.

`next`...FIXME

=== [[hasNext]] `hasNext` Method

[source, scala]
----
hasNext: Boolean
----

NOTE: `hasNext` is part of Scala's http://www.scala-lang.org/api/2.11.11/#scala.collection.Iterator[scala.collection.Iterator] interface that tests whether this iterator can provide another element.

`hasNext`...FIXME

=== [[creating-instance]] Creating TungstenAggregationIterator Instance

`TungstenAggregationIterator` takes the following when created:

* [[partIndex]] Partition index
* [[groupingExpressions]] Grouping <<spark-sql-Expression-NamedExpression.adoc#, named expressions>>
* [[aggregateExpressions]] <<spark-sql-Expression-AggregateExpression.adoc#, Aggregate expressions>>
* [[aggregateAttributes]] Aggregate <<spark-sql-Expression-Attribute.adoc#, attributes>>
* [[initialInputBufferOffset]] Initial input buffer offset
* [[resultExpressions]] Output <<spark-sql-Expression-NamedExpression.adoc#, named expressions>>
* [[newMutableProjection]] Function to create a new `MutableProjection` given Catalyst expressions and attributes (i.e. `(Seq[Expression], Seq[Attribute]) => MutableProjection`)
* [[originalInputAttributes]] Output attributes (of the <<spark-sql-SparkPlan-HashAggregateExec.adoc#child, child>> of the <<spark-sql-SparkPlan-HashAggregateExec.adoc#, HashAggregateExec>> physical operator)
* [[inputIter]] Iterator of <<spark-sql-InternalRow.adoc#, InternalRows>> (from a single partition of the <<spark-sql-SparkPlan-HashAggregateExec.adoc#child, child>> of the <<spark-sql-SparkPlan-HashAggregateExec.adoc#, HashAggregateExec>> physical operator)
* [[testFallbackStartsAt]] (used for testing) Optional ``HashAggregateExec``'s link:spark-sql-SparkPlan-HashAggregateExec.adoc#testFallbackStartsAt[testFallbackStartsAt]
* [[numOutputRows]] `numOutputRows` <<spark-sql-SQLMetric.adoc#, SQLMetric>>
* [[peakMemory]] `peakMemory` <<spark-sql-SQLMetric.adoc#, SQLMetric>>
* [[spillSize]] `spillSize` <<spark-sql-SQLMetric.adoc#, SQLMetric>>
* [[avgHashProbe]] `avgHashProbe` <<spark-sql-SQLMetric.adoc#, SQLMetric>>

`TungstenAggregationIterator` initializes the <<internal-registries, internal registries and counters>>.

=== [[generateResultProjection]] `generateResultProjection` Method

[source, scala]
----
generateResultProjection(): (UnsafeRow, InternalRow) => UnsafeRow
----

NOTE: `generateResultProjection` is part of the <<spark-sql-AggregationIterator.adoc#generateResultProjection, AggregationIterator Contract>> to...FIXME.

`generateResultProjection`...FIXME

=== [[outputForEmptyGroupingKeyWithoutInput]] `outputForEmptyGroupingKeyWithoutInput` Method

[source, scala]
----
outputForEmptyGroupingKeyWithoutInput(): UnsafeRow
----

`outputForEmptyGroupingKeyWithoutInput`...FIXME

NOTE: `outputForEmptyGroupingKeyWithoutInput` is used when...FIXME
