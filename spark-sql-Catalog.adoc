== [[Catalog]] Catalog -- Metastore Management Interface

`Catalog` is the <<contract, interface>> for working with a *metastore* (aka _metadata catalog_) of relational entities, e.g. database(s), tables, functions, table columns, and temporary views.

You can access the current catalog using link:spark-sql-SparkSession.adoc#catalog[SparkSession.catalog] property.

[source, scala]
----
scala> spark.version
res0: String = 2.3.0

scala> :type spark
org.apache.spark.sql.SparkSession

scala> :type spark.catalog
org.apache.spark.sql.catalog.Catalog
----

NOTE: link:spark-sql-CatalogImpl.adoc[CatalogImpl] is the `Catalog` in Spark SQL.

=== [[contract]] Catalog Contract

[source, scala]
----
package org.apache.spark.sql.catalog

abstract class Catalog {
  def cacheTable(tableName: String): Unit
  def cacheTable(tableName: String, storageLevel: StorageLevel): Unit
  def currentDatabase: String
  def setCurrentDatabase(dbName: String): Unit
  def listDatabases(): Dataset[Database]
  def listTables(): Dataset[Table]
  def listTables(dbName: String): Dataset[Table]
  def listFunctions(): Dataset[Function]
  def listFunctions(dbName: String): Dataset[Function]
  def listColumns(tableName: String): Dataset[Column]
  def listColumns(dbName: String, tableName: String): Dataset[Column]
  def createExternalTable(tableName: String, path: String): DataFrame
  def createExternalTable(tableName: String, path: String, source: String): DataFrame
  def createExternalTable(
      tableName: String,
      source: String,
      options: Map[String, String]): DataFrame
  def createExternalTable(
      tableName: String,
      source: String,
      schema: StructType,
      options: Map[String, String]): DataFrame
  def createTable(
      tableName: String,
      source: String,
      schema: StructType,
      options: Map[String, String]): DataFrame
  def getTable(tableName: String): Table
  def getTable(dbName: String, tableName: String): Table
  def dropTempView(viewName: String): Unit
  def isCached(tableName: String): Boolean
  def uncacheTable(tableName: String): Unit
  def clearCache(): Unit
  def refreshTable(tableName: String): Unit
  def refreshByPath(path: String): Unit
  def functionExists(functionName: String): Boolean
  def functionExists(dbName: String, functionName: String): Boolean
}
----

.Catalog Contract
[cols="1,2",options="header",width="100%"]
|===
| Method
| Description

| [[cacheTable]] `cacheTable`
| Caches the specified table in memory

Used for SQL's link:spark-sql-caching.adoc#cache-table[CACHE TABLE] and `AlterTableRenameCommand` command.

| [[createTable]] `createTable`
|

| [[functionExists]] `functionExists`
|

| [[getTable]] `getTable`
|

| [[listTables]] `listTables`
| Gives a list of tables in the specified database

| [[refreshByPath]] `refreshByPath`
|
|===
