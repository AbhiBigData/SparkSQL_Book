== [[FileScanRDD]] FileScanRDD -- Input RDD of FileSourceScanExec Physical Operator

`FileScanRDD` is an `RDD` of link:spark-sql-InternalRow.adoc[internal binary rows] (i.e. `RDD[InternalRow]`) that is <<creating-instance, created>> exclusively when `FileSourceScanExec` physical operator is requested to link:spark-sql-SparkPlan-FileSourceScanExec.adoc#createBucketedReadRDD[createBucketedReadRDD] and link:spark-sql-SparkPlan-FileSourceScanExec.adoc#createNonBucketedReadRDD[createNonBucketedReadRDD] (which is when `FileSourceScanExec` is requested for the link:spark-sql-SparkPlan-FileSourceScanExec.adoc#inputRDD[input RDD] that `WholeStageCodegenExec` physical operator uses when link:spark-sql-SparkPlan-WholeStageCodegenExec.adoc#doExecute[executed]).

[[internal-registries]]
.FileScanRDD's Internal Properties (e.g. Registries, Counters and Flags)
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[ignoreCorruptFiles]] `ignoreCorruptFiles`
| Controls...FIXME

Used when...FIXME

| [[ignoreMissingFiles]] `ignoreMissingFiles`
| Controls...FIXME

Used when...FIXME
|===

=== [[getPreferredLocations]] `getPreferredLocations` Method

[source, scala]
----
getPreferredLocations(split: RDDPartition): Seq[String]
----

NOTE: `getPreferredLocations` is part of the RDD Contract to...FIXME.

`getPreferredLocations`...FIXME

NOTE: `getPreferredLocations` is used when...FIXME

=== [[getPartitions]] `getPartitions` Method

[source, scala]
----
getPartitions: Array[RDDPartition]
----

NOTE: `getPartitions` is part of the RDD Contract to...FIXME.

`getPartitions`...FIXME

=== [[compute]] `compute` Method

[source, scala]
----
compute(split: RDDPartition, context: TaskContext): Iterator[InternalRow]
----

NOTE: `compute` is part of the RDD Contract to...FIXME.

`compute`...FIXME

=== [[creating-instance]] Creating FileScanRDD Instance

`FileScanRDD` takes the following when created:

* [[sparkSession]] link:spark-sql-SparkSession.adoc[SparkSession]
* [[readFunction]] Read function that takes a link:spark-sql-PartitionedFile.adoc[PartitionedFile] and gives link:spark-sql-InternalRow.adoc[internal rows] back (i.e. `(PartitionedFile) => Iterator[InternalRow]`)
* [[filePartitions]] `FilePartitions`
