== Dataset API -- Untyped Transformations

*Untyped transformations* are part of the Dataset API for transforming a `Dataset` to a <<spark-sql-DataFrame.adoc#, DataFrame>>, a <<spark-sql-Column.adoc#, Column>>, a <<spark-sql-RelationalGroupedDataset.adoc#, RelationalGroupedDataset>>, a <<spark-sql-DataFrameNaFunctions.adoc#, DataFrameNaFunctions>> or a <<spark-sql-DataFrameStatFunctions.adoc#, DataFrameStatFunctions>> (and hence _untyped_).

[[methods]]
.Dataset API's Untyped Transformations
[cols="1,2",options="header",width="100%"]
|===
| Transformation
| Description

| <<agg, agg>>
a|

[source, scala]
----
agg(aggExpr: (String, String), aggExprs: (String, String)*): DataFrame
agg(exprs: Map[String, String]): DataFrame
agg(exprs: java.util.Map[String, String]): DataFrame
agg(expr: Column, exprs: Column*): DataFrame
----

| <<apply, apply>>
a| Selects a column based on the column name (i.e. maps a `Dataset` onto a `Column`)

[source, scala]
----
apply(colName: String): Column
----

| <<checkpoint, checkpoint>>
a|

[source, scala]
----
checkpoint(): Dataset[T]
checkpoint(eager: Boolean): Dataset[T]
----

| <<col, col>>
a| Selects a column based on the column name (i.e. maps a `Dataset` onto a `Column`)

[source, scala]
----
col(colName: String): Column
----

| <<colRegex, colRegex>>
a| (*New in 2.3.0*) Selects a column based on the column name specified as a regex (i.e. maps a `Dataset` onto a `Column`)

[source, scala]
----
colRegex(colName: String): Column
----

| <<crossJoin, crossJoin>>
a|

[source, scala]
----
crossJoin(right: Dataset[_]): DataFrame
----

| <<cube, cube>>
a|

[source, scala]
----
cube(cols: Column*): RelationalGroupedDataset
cube(col1: String, cols: String*): RelationalGroupedDataset
----

| <<drop, drop>>
a|

[source, scala]
----
drop(colName: String): DataFrame
drop(colNames: String*): DataFrame
drop(col: Column): DataFrame
----

| <<groupBy, groupBy>>
a|

[source, scala]
----
groupBy(cols: Column*): RelationalGroupedDataset
groupBy(col1: String, cols: String*): RelationalGroupedDataset
----

| <<join, join>>
a|

[source, scala]
----
join(right: Dataset[_]): DataFrame
join(right: Dataset[_], usingColumn: String): DataFrame
join(right: Dataset[_], usingColumns: Seq[String]): DataFrame
join(right: Dataset[_], usingColumns: Seq[String], joinType: String): DataFrame
join(right: Dataset[_], joinExprs: Column): DataFrame
join(right: Dataset[_], joinExprs: Column, joinType: String): DataFrame
----

| <<localCheckpoint, localCheckpoint>>
a| (*New in 2.3.0*)

[source, scala]
----
localCheckpoint(): Dataset[T]
localCheckpoint(eager: Boolean): Dataset[T]
----

| <<na, na>>
a|

[source, scala]
----
na: DataFrameNaFunctions
----

| <<rollup, rollup>>
a|

[source, scala]
----
rollup(cols: Column*): RelationalGroupedDataset
rollup(col1: String, cols: String*): RelationalGroupedDataset
----

| <<select, select>>
a|

[source, scala]
----
select(cols: Column*): DataFrame
select(col: String, cols: String*): DataFrame
----

| <<selectExpr, selectExpr>>
a|

[source, scala]
----
selectExpr(exprs: String*): DataFrame
----

| <<stat, stat>>
a|

[source, scala]
----
stat: DataFrameStatFunctions
----

| <<toDF, toDF>>
a|

[source, scala]
----
toDF(): DataFrame
----

| <<withColumn, withColumn>>
a|

[source, scala]
----
withColumn(colName: String, col: Column): DataFrame
----

| <<withColumnRenamed, withColumnRenamed>>
a|

[source, scala]
----
withColumnRenamed(existingName: String, newName: String): DataFrame
----
|===

=== [[agg]] `agg` Untyped Transformation

[source, scala]
----
agg(aggExpr: (String, String), aggExprs: (String, String)*): DataFrame
agg(exprs: Map[String, String]): DataFrame
agg(exprs: java.util.Map[String, String]): DataFrame
agg(expr: Column, exprs: Column*): DataFrame
----

`agg`...FIXME

=== [[apply]] `apply` Untyped Transformation

[source, scala]
----
apply(colName: String): Column
----

`apply` selects a column based on the column name (i.e. maps a `Dataset` onto a `Column`).

=== [[checkpoint]] `checkpoint` Untyped Transformation

[source, scala]
----
checkpoint(): Dataset[T]
checkpoint(eager: Boolean): Dataset[T]
----

`checkpoint`...FIXME

=== [[col]] `col` Untyped Transformation

[source, scala]
----
col(colName: String): Column
----

`col` selects a column based on the column name (i.e. maps a `Dataset` onto a `Column`).

=== [[colRegex]] `colRegex` Untyped Transformation

[source, scala]
----
colRegex(colName: String): Column
----

(*New in 2.3.0*) `colRegex` selects a column based on the column name specified as a regex (i.e. maps a `Dataset` onto a `Column`).

=== [[crossJoin]] `crossJoin` Untyped Transformation

[source, scala]
----
crossJoin(right: Dataset[_]): DataFrame
----

`crossJoin`...FIXME

=== [[cube]] `cube` Untyped Transformation

[source, scala]
----
cube(cols: Column*): RelationalGroupedDataset
cube(col1: String, cols: String*): RelationalGroupedDataset
----

`cube`...FIXME

=== [[drop]] `drop` Untyped Transformation

[source, scala]
----
drop(colName: String): DataFrame
drop(colNames: String*): DataFrame
drop(col: Column): DataFrame
----

`drop`...FIXME

=== [[groupBy]] `groupBy` Untyped Transformation

[source, scala]
----
groupBy(cols: Column*): RelationalGroupedDataset
groupBy(col1: String, cols: String*): RelationalGroupedDataset
----

`groupBy`...FIXME

=== [[join]] `join` Untyped Transformation

[source, scala]
----
join(right: Dataset[_]): DataFrame
join(right: Dataset[_], usingColumn: String): DataFrame
join(right: Dataset[_], usingColumns: Seq[String]): DataFrame
join(right: Dataset[_], usingColumns: Seq[String], joinType: String): DataFrame
join(right: Dataset[_], joinExprs: Column): DataFrame
join(right: Dataset[_], joinExprs: Column, joinType: String): DataFrame
----

`join`...FIXME

=== [[localCheckpoint]] `localCheckpoint` Untyped Transformation

[source, scala]
----
localCheckpoint(): Dataset[T]
localCheckpoint(eager: Boolean): Dataset[T]
----

(*New in 2.3.0*) `localCheckpoint`...FIXME

=== [[na]] `na` Untyped Transformation

[source, scala]
----
na: DataFrameNaFunctions
----

`na` simply creates a <<spark-sql-DataFrameNaFunctions.adoc#, DataFrameNaFunctions>> to work with missing data.

=== [[rollup]] `rollup` Untyped Transformation

[source, scala]
----
rollup(cols: Column*): RelationalGroupedDataset
rollup(col1: String, cols: String*): RelationalGroupedDataset
----

`rollup`...FIXME

=== [[select]] `select` Untyped Transformation

[source, scala]
----
select(cols: Column*): DataFrame
select(col: String, cols: String*): DataFrame
----

`select`...FIXME

=== [[selectExpr]] `selectExpr` Untyped Transformation

[source, scala]
----
selectExpr(exprs: String*): DataFrame
----

`selectExpr`...FIXME

=== [[stat]] `stat` Untyped Transformation

[source, scala]
----
stat: DataFrameStatFunctions
----

`stat` simply creates a <<spark-sql-DataFrameStatFunctions.adoc#, DataFrameStatFunctions>> to work with statistic functions.

=== [[toDF]] `toDF` Untyped Transformation

[source, scala]
----
toDF(): DataFrame
----

`toDF`...FIXME

=== [[withColumn]] `withColumn` Untyped Transformation

[source, scala]
----
withColumn(colName: String, col: Column): DataFrame
----

`withColumn`...FIXME

=== [[withColumnRenamed]] `withColumnRenamed` Untyped Transformation

[source, scala]
----
withColumnRenamed(existingName: String, newName: String): DataFrame
----

`withColumnRenamed`...FIXME
